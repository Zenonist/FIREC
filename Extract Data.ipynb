{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bb5d83",
   "metadata": {},
   "source": [
    "# Extract list of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6386dc8",
   "metadata": {},
   "source": [
    "### Masked dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e6d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "file = open(\"Masked_dataset_20id.txt\",\"w\")\n",
    "\n",
    "folder_list = os.listdir(r\"D:/GitHub/MaskTheFace/datasets_masked\")\n",
    "for folder in folder_list:\n",
    "    imagelist_masked = glob.glob(r\"D:/GitHub/MaskTheFace/datasets_masked/\" + str(folder) + \"/*.jpg\")\n",
    "    for image_mask in imagelist_masked:  \n",
    "        file.write(image_mask + \" \\n\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96556adb",
   "metadata": {},
   "source": [
    "### Train dataset 50 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "file = open(\"Train_dataset_50id.txt\",\"w\")\n",
    "\n",
    "folder_list = os.listdir(r\"D:/VGG_Face_Dataset/Train_50\")\n",
    "for folder in folder_list:\n",
    "    imagelist_masked = glob.glob(r\"D:/VGG_Face_Dataset/Train_50/\" + str(folder) + \"/*.jpg\")\n",
    "    for image_mask in imagelist_masked:  \n",
    "        file.write(image_mask + \" \\n\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68cf7d2",
   "metadata": {},
   "source": [
    "### Train dataset 20 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "file = open(\"Train_dataset_20id.txt\",\"w\")\n",
    "\n",
    "folder_list = os.listdir(r\"D:/VGG_Face_Dataset/Train_20\")\n",
    "for folder in folder_list:\n",
    "    imagelist_masked = glob.glob(r\"D:/VGG_Face_Dataset/Train_20/\" + str(folder) + \"/*.jpg\")\n",
    "    for image_mask in imagelist_masked:  \n",
    "        file.write(image_mask + \" \\n\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b80bf",
   "metadata": {},
   "source": [
    "# Extract the vector of each image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f4ec0d",
   "metadata": {},
   "source": [
    "### Masked dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffdf860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "from deepface import DeepFace\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "file = open(\"C:/Users/ASUS/Desktop/Github/Face_Recognition_with_mask/Data/Masked_dataset_50id_vector.txt\",\"w\")\n",
    "count = 0\n",
    "folder_list = os.listdir(r\"D:/GitHub/MaskTheFace/datasets_masked\")\n",
    "for folder in folder_list:\n",
    "    imagelist_masked = glob.glob(r\"D:/GitHub/MaskTheFace/datasets_masked/\" + str(folder) + \"/*.jpg\")\n",
    "    for image_mask in imagelist_masked:\n",
    "        tic = time.time()\n",
    "        vector = DeepFace.represent(img_path = image_mask, enforce_detection = False)\n",
    "        obj = DeepFace.analyze(img_path = image_mask, actions = ['age', 'gender', 'race'], enforce_detection=False)\n",
    "        vector_string = \" \".join(map(str, vector))\n",
    "        obj_age_string = \" \".join(map(str, obj[\"age\"]))\n",
    "        obj_gender_string = \" \".join(map(str, obj[\"gender\"]))\n",
    "        file.write(image_mask + \"|\" + vector_string + \"|\" + obj_age_string + \"|\" + obj_gender_string + \"|\" + str(obj[\"race\"]['asian']) + \" \" + str(obj[\"race\"]['indian'])\n",
    "                    + \" \" + str(obj[\"race\"]['black']) + \" \" + str(obj[\"race\"]['white']) + \" \" + str(obj[\"race\"]['middle eastern']) + \" \" + str(obj[\"race\"]['latino hispanic']) +\" \\n\")\n",
    "        count += 1\n",
    "        print('Count: ' + str(count))\n",
    "        toc = time.time()\n",
    "        print(\"It takes only \",toc-tic,\" seconds\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe7f006",
   "metadata": {},
   "source": [
    "### Train dataset Without masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32311ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "from deepface import DeepFace\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "TIC = time.time()\n",
    "file = open(\"C:/Users/ASUS/Desktop/Github/Face_Recognition_with_mask/Data/Train_dataset_50id_vector_Non_masked.txt\",\"a\")\n",
    "count = 0\n",
    "folder_list = os.listdir(r\"D:/VGG_Face_Dataset/Train_50\")\n",
    "for folder in folder_list:\n",
    "    imagelist = glob.glob(r\"D:/VGG_Face_Dataset/Train_50/\" + str(folder) + \"/*.jpg\")\n",
    "    for image in imagelist:\n",
    "        tic = time.time()\n",
    "        vector = DeepFace.represent(img_path = image, enforce_detection = False)\n",
    "        obj = DeepFace.analyze(img_path = image, actions = ['age', 'gender', 'race'], enforce_detection=False)\n",
    "        vector_string = \" \".join(map(str, vector))\n",
    "        obj_age_string = \" \".join(map(str, obj[\"age\"]))\n",
    "        obj_gender_string = \" \".join(map(str, obj[\"gender\"]))\n",
    "        file.write(image + \"|\" + vector_string + \"|\" + obj_age_string + \"|\" + obj_gender_string + \"|\" + str(obj[\"race\"]['asian']) + \" \" + str(obj[\"race\"]['indian'])\n",
    "                    + \" \" + str(obj[\"race\"]['black']) + \" \" + str(obj[\"race\"]['white']) + \" \" + str(obj[\"race\"]['middle eastern']) + \" \" + str(obj[\"race\"]['latino hispanic']) +\" \\n\")\n",
    "        count += 1\n",
    "        print('Count: ' + str(count))\n",
    "        print('image: ' + image)\n",
    "        toc = time.time()\n",
    "        print(\"It takes only \",toc-tic,\" seconds\")\n",
    "\n",
    "file.close()\n",
    "TOC = time.time()\n",
    "print(\"It totally takes only \",TOC-TIC,\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616e187",
   "metadata": {},
   "source": [
    "### Train dataset With masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "from deepface import DeepFace\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "TIC = time.time()\n",
    "file = open(\"C:/Users/ASUS/Desktop/Github/Face_Recognition_with_mask/Data/Train_dataset_50id_vector_masked.txt\",\"a\")\n",
    "count = 0\n",
    "folder_list = os.listdir(r\"D:/VGG_Face_Dataset/Train_50_masked\")\n",
    "for folder in folder_list:\n",
    "    imagelist = glob.glob(r\"D:/VGG_Face_Dataset/Train_50_masked/\" + str(folder) + \"/*.jpg\")\n",
    "    for image in imagelist:\n",
    "        tic = time.time()\n",
    "        vector = DeepFace.represent(img_path = image, enforce_detection = False)\n",
    "        obj = DeepFace.analyze(img_path = image, actions = ['age', 'gender', 'race'], enforce_detection=False)\n",
    "        vector_string = \" \".join(map(str, vector))\n",
    "        obj_age_string = \" \".join(map(str, obj[\"age\"]))\n",
    "        obj_gender_string = \" \".join(map(str, obj[\"gender\"]))\n",
    "        file.write(image + \"|\" + vector_string + \"|\" + obj_age_string + \"|\" + obj_gender_string + \"|\" + str(obj[\"race\"]['asian']) + \" \" + str(obj[\"race\"]['indian'])\n",
    "                    + \" \" + str(obj[\"race\"]['black']) + \" \" + str(obj[\"race\"]['white']) + \" \" + str(obj[\"race\"]['middle eastern']) + \" \" + str(obj[\"race\"]['latino hispanic']) +\" \\n\")\n",
    "        count += 1\n",
    "        print('Count: ' + str(count))\n",
    "        print('image: ' + image)\n",
    "        toc = time.time()\n",
    "        print(\"It takes only \",toc-tic,\" seconds\")\n",
    "\n",
    "file.close()\n",
    "TOC = time.time()\n",
    "print(\"It totally takes only \",TOC-TIC,\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774d478",
   "metadata": {},
   "source": [
    "### Test dataset Without masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f974c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "from deepface import DeepFace\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "TIC = time.time()\n",
    "file = open(\"C:/Users/ASUS/Desktop/Github/Face_Recognition_with_mask/Data/Test_dataset_50id_vector.txt\",\"w\")\n",
    "count = 0\n",
    "folder_list = os.listdir(r\"D:/VGG_Face_Dataset/Test_50\")\n",
    "for folder in folder_list:\n",
    "    imagelist = glob.glob(r\"D:/VGG_Face_Dataset/Test_50/\" + str(folder) + \"/*.jpg\")\n",
    "    for image in imagelist:\n",
    "        tic = time.time()\n",
    "        vector = DeepFace.represent(img_path = image, enforce_detection = False)\n",
    "        obj = DeepFace.analyze(img_path = image, actions = ['age', 'gender', 'race'], enforce_detection=False)\n",
    "        vector_string = \" \".join(map(str, vector))\n",
    "        obj_age_string = \" \".join(map(str, obj[\"age\"]))\n",
    "        obj_gender_string = \" \".join(map(str, obj[\"gender\"]))\n",
    "        file.write(image + \"|\" + vector_string + \"|\" + obj_age_string + \"|\" + obj_gender_string + \"|\" + str(obj[\"race\"]['asian']) + \" \" + str(obj[\"race\"]['indian'])\n",
    "                    + \" \" + str(obj[\"race\"]['black']) + \" \" + str(obj[\"race\"]['white']) + \" \" + str(obj[\"race\"]['middle eastern']) + \" \" + str(obj[\"race\"]['latino hispanic']) +\" \\n\")\n",
    "        count += 1\n",
    "        print('Count: ' + str(count))\n",
    "        print('image: ' + image)\n",
    "        toc = time.time()\n",
    "        print(\"It takes only \",toc-tic,\" seconds\")\n",
    "\n",
    "file.close()\n",
    "TOC = time.time()\n",
    "print(\"It totally takes only \",TOC-TIC,\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7876d458-2ad5-4026-a822-887dcc101ca5",
   "metadata": {},
   "source": [
    "### Test dataset With masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e21ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "from deepface import DeepFace\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "TIC = time.time()\n",
    "file = open(\"C:/Users/ASUS/Desktop/Github/Face_Recognition_with_mask/Data/Test_dataset_50id_vector_Masked_Ver_2.txt\",\"w\")\n",
    "count = 0\n",
    "folder_list = os.listdir(r\"D:/VGG_Face_Dataset/Test_50_masked\")\n",
    "for folder in folder_list:\n",
    "    imagelist = glob.glob(r\"D:/VGG_Face_Dataset/Test_50_masked/\" + str(folder) + \"/*.jpg\")\n",
    "    for image in imagelist:\n",
    "        tic = time.time()\n",
    "        vector = DeepFace.represent(img_path = image, enforce_detection = False)\n",
    "        obj = DeepFace.analyze(img_path = image, actions = ['age', 'gender', 'race'], enforce_detection=False)\n",
    "        vector_string = \" \".join(map(str, vector))\n",
    "        obj_age_string = \" \".join(map(str, obj[\"age\"]))\n",
    "        obj_gender_string = \" \".join(map(str, obj[\"gender\"]))\n",
    "        file.write(image + \"|\" + vector_string + \"|\" + obj_age_string + \"|\" + obj_gender_string + \"|\" + str(obj[\"race\"]['asian']) + \" \" + str(obj[\"race\"]['indian'])\n",
    "                    + \" \" + str(obj[\"race\"]['black']) + \" \" + str(obj[\"race\"]['white']) + \" \" + str(obj[\"race\"]['middle eastern']) + \" \" + str(obj[\"race\"]['latino hispanic']) +\" \\n\")\n",
    "        count += 1\n",
    "        print('Count: ' + str(count))\n",
    "        print('image: ' + image)\n",
    "        toc = time.time()\n",
    "        print(\"It takes only \",toc-tic,\" seconds\")\n",
    "\n",
    "file.close()\n",
    "TOC = time.time()\n",
    "print(\"It totally takes only \",TOC-TIC,\" seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
